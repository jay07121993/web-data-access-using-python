{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from scrapy.selector import Selector \n",
    "import justext\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2(1) Extract Html document from URL\n",
    "def extractHtml(my_url):\n",
    "    page = requests.get(my_url)\n",
    "    soup = BeautifulSoup(page.text,'lxml')\n",
    "    #print(soup.prettify())\n",
    "    print(soup.get_text)\n",
    "    #print(\" \".join(soup.strings))\n",
    "extractHtml(\"https://www.google.com/\")\n",
    "#f= open(\"./page.html\",\"w+\") #to create html page\n",
    "#f.write(page.text)\n",
    "\n",
    "#print(page.headers)\n",
    "\n",
    "#print(\"Status :\",page.status_code) # check Http status\n",
    "\n",
    "#print(page.url) # print url\n",
    "\n",
    "#print(page.content) # access html content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task2(2)  Extract plain text from html document\n",
    "def plainText(my_url1):\n",
    "    page = requests.get(my_url1)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    \n",
    "    # kill all script and style elements\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()\n",
    "    text = soup.get_text() #get text\n",
    "    \n",
    "    # break into lines and remove leading and trailing space on each\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    # break multi-headlines into a line each\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    # drop blank lines\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "    print(text)\n",
    "plainText(\"https://www.facebook.com/\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task2(3) Extract only Boilerplate content from Html\n",
    "#Extract only boilerplate content from Html\n",
    "def boilerPlateContent(url):\n",
    "    html = requests.get(url)\n",
    "    par = justext.justext(html.content, justext.get_stoplist(\"English\"))\n",
    "    boiler=[p.text for p in par if p.is_boilerplate]\n",
    "    print(boiler)\n",
    "boilerPlateContent(\"https://www.bing.com\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task3 Extract keyword from list which is present in text \n",
    "list=['Germany','India']\n",
    "text=['Germany is good for Automotive industry']\n",
    "for country in list:\n",
    "    if country in text[0]:\n",
    "        print(country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task:4 structured information from the following url\n",
    "#Access the HTML page\n",
    "def structured_info(url):\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.text,'lxml')\n",
    "\n",
    "    #Extract Company Names\n",
    "    company_name = []\n",
    "    pre=soup.findAll('h2')\n",
    "    for i in pre:\n",
    "        body = str(i)\n",
    "        de= Selector(text=body).xpath('//a/text()').extract()\n",
    "        company_name.append(de)\n",
    "    print(list(itertools.chain.from_iterable(company_name)))   \n",
    "\n",
    "    #extract telephone number\n",
    "    allrows = soup.find_all('span', 'telephone')\n",
    "    print(\"total items found:\",len(allrows))\n",
    "\n",
    "    telephone_number=[]\n",
    "    for row in allrows:\n",
    "        num = row.find('span', 'value').text.strip()\n",
    "        telephone_number.append(num)\n",
    "    print(telephone_number) \n",
    "structured_info('https://www.gmdu.net/list-1-p1.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
